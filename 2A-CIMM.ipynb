{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f570305f",
   "metadata": {},
   "source": [
    "## Import Liabraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93f690ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten\n",
    "import time\n",
    "import tkinter as tk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d1c22",
   "metadata": {},
   "source": [
    "## Load Dataset via Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9cc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load IMDB dataset\n",
    "num_words = 10000  # Vocabulary size\n",
    "max_len = 100  # Maximum length of each review\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8f4cb0",
   "metadata": {},
   "source": [
    "##  Make sequences of equal length for nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b7cd1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences \n",
    "x_train = pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f4352",
   "metadata": {},
   "source": [
    "## 1. Embedding Layer: Integer-encoded words-> dense vectors.\n",
    "   \n",
    "## 2. Flatten Layer: Embedding layer's output->1D array.\n",
    "\n",
    "## 3. Dense Layer: Single output->representing the probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9aa83e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:86: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, 32, input_length=max_len))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1905eea",
   "metadata": {},
   "source": [
    "##  Train Model for 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4dc6e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6565 - loss: 0.6011 - val_accuracy: 0.8488 - val_loss: 0.3400\n",
      "Epoch 2/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9014 - loss: 0.2584 - val_accuracy: 0.8519 - val_loss: 0.3354\n",
      "Epoch 3/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9565 - loss: 0.1500 - val_accuracy: 0.8491 - val_loss: 0.3510\n",
      "Epoch 4/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9886 - loss: 0.0713 - val_accuracy: 0.8457 - val_loss: 0.3783\n",
      "Epoch 5/5\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0302 - val_accuracy: 0.8432 - val_loss: 0.4178\n",
      "Training Time: 6.130273103713989 seconds\n",
      "Total Training Loss: 0.9882840923964977\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "start_time = time.time()\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Training Time:\", training_time, \"seconds\")\n",
    "\n",
    "# Calculate total training loss\n",
    "total_training_loss = sum(history.history['loss'])\n",
    "print(\"Total Training Loss:\", total_training_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3573c3b",
   "metadata": {},
   "source": [
    "## GUI via Tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b542b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "Prediction Time: 1.183746099472046 seconds\n"
     ]
    }
   ],
   "source": [
    "# GUI using Tkinter\n",
    "def classify_review():\n",
    "    start_time = time.time()\n",
    "    review = entry.get()\n",
    "    words = review.split()\n",
    "    encoded_review = [1]  # IMDB dataset starts encoding from 1\n",
    "    for word in words:\n",
    "        encoded_word = imdb.get_word_index().get(word.lower(), 0) + 3\n",
    "        if encoded_word < num_words:\n",
    "            encoded_review.append(encoded_word)\n",
    "    encoded_review = pad_sequences([encoded_review], maxlen=max_len)\n",
    "    prediction = model.predict(encoded_review)[0][0]\n",
    "    end_time = time.time()\n",
    "    prediction_time = end_time - start_time\n",
    "    if prediction >= 0.5:\n",
    "        result_label.config(text=\"Positive review\")\n",
    "    else:\n",
    "        result_label.config(text=\"Negative review\")\n",
    "    print(\"Prediction Time:\", prediction_time, \"seconds\")\n",
    "\n",
    "# Create GUI\n",
    "root = tk.Tk()\n",
    "root.title(\"Movie Review using IMDB dataset\")\n",
    "\n",
    "entry = tk.Entry(root, width=50)\n",
    "entry.pack(pady=10)\n",
    "\n",
    "classify_button = tk.Button(root, text=\"Classify\", command=classify_review)\n",
    "classify_button.pack(pady=5)\n",
    "\n",
    "result_label = tk.Label(root, text=\"\")\n",
    "result_label.pack(pady=5)\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5863024f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd42e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
